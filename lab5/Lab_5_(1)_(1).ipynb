{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGExifOvrMXe",
        "outputId": "3dc38f19-60ec-4560-f984-5fea4bff9224"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.29)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.3-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.11.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.3 alembic-1.13.1 colorlog-6.8.2 optuna-3.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1V33RyparJOH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4328342-f983-41b0-bc15-482bee1f2e1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "2110848/2110848 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import optuna\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import reuters\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load the Reuters dataset\n",
        "max_len = 300  # Adjust based on the dataset analysis\n",
        "(X_train, y_train), (X_test, y_test) = reuters.load_data(path=\"reuters.npz\")\n",
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)\n",
        "\n",
        "# Convert the data to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# Create a DataLoader\n",
        "batch_size = 32\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, n_hidden, n_units, dropout_rate):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        layers = [nn.Linear(input_dim, n_units), nn.ReLU(), nn.Dropout(dropout_rate)]\n",
        "\n",
        "        for _ in range(n_hidden):\n",
        "            layers += [nn.Linear(n_units, n_units), nn.ReLU(), nn.Dropout(dropout_rate)]\n",
        "\n",
        "        layers += [nn.Linear(n_units, output_dim)]\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # Flatten the input\n",
        "        logits = self.network(x)\n",
        "        return logits\n",
        "\n",
        "def create_model(trial, input_dim, output_dim):\n",
        "    n_hidden = trial.suggest_int('n_hidden', 2, 5)  # Increased range for hidden layers\n",
        "    n_units = trial.suggest_int('n_units', 64, 256)  # Increased range for units per layer\n",
        "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)  # Suggesting dropout rate\n",
        "    model = NeuralNetwork(input_dim, output_dim, n_hidden, n_units, dropout_rate)\n",
        "    return model\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    model = create_model(trial, X_train.shape[1], len(np.unique(y_train)))\n",
        "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            output = model(X_batch)\n",
        "            loss = criterion(output, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            output = model(X_batch)\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total += y_batch.size(0)\n",
        "            correct += (predicted == y_batch).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=10, n_jobs=-1)  # Reduced the number of trials for brevity\n",
        "\n",
        "print(study.best_params)\n",
        "\n",
        "# Create a model with the best hyperparameters found\n",
        "best_model = create_model(study.best_trial, X_train.shape[1], len(np.unique(y_train)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCuQrqS7wKTv",
        "outputId": "15d70cee-29a0-439f-cc0e-4e6d909dde08"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-29 23:15:27,451] A new study created in memory with name: no-name-4f16d8f4-04f2-4a12-8558-f6c82b3cea8f\n",
            "<ipython-input-2-0ea501dfce52>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
            "[I 2024-04-29 23:15:56,154] Trial 0 finished with value: 0.37934105075690117 and parameters: {'n_hidden': 5, 'n_units': 179, 'dropout_rate': 0.49605091496784925, 'learning_rate': 5.356339767565198e-05}. Best is trial 0 with value: 0.37934105075690117.\n",
            "<ipython-input-2-0ea501dfce52>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
            "[I 2024-04-29 23:16:04,448] Trial 1 finished with value: 0.3619768477292965 and parameters: {'n_hidden': 4, 'n_units': 167, 'dropout_rate': 0.21292832304818307, 'learning_rate': 0.0050759796550880615}. Best is trial 0 with value: 0.37934105075690117.\n",
            "[I 2024-04-29 23:16:17,281] Trial 2 finished with value: 0.2773820124666073 and parameters: {'n_hidden': 2, 'n_units': 249, 'dropout_rate': 0.4957150897922328, 'learning_rate': 1.6660040028371906e-05}. Best is trial 0 with value: 0.37934105075690117.\n",
            "[I 2024-04-29 23:16:31,617] Trial 3 finished with value: 0.3637577916295637 and parameters: {'n_hidden': 4, 'n_units': 175, 'dropout_rate': 0.33279408927601806, 'learning_rate': 0.0005584737881467798}. Best is trial 0 with value: 0.37934105075690117.\n",
            "[I 2024-04-29 23:16:42,477] Trial 4 finished with value: 0.36420302760463047 and parameters: {'n_hidden': 2, 'n_units': 233, 'dropout_rate': 0.2080821275471262, 'learning_rate': 0.0005072666573477355}. Best is trial 0 with value: 0.37934105075690117.\n",
            "[I 2024-04-29 23:16:58,854] Trial 5 finished with value: 0.3873552983081033 and parameters: {'n_hidden': 3, 'n_units': 171, 'dropout_rate': 0.23599819193024688, 'learning_rate': 0.000823571972729172}. Best is trial 5 with value: 0.3873552983081033.\n",
            "[I 2024-04-29 23:17:12,250] Trial 6 finished with value: 0.3619768477292965 and parameters: {'n_hidden': 4, 'n_units': 122, 'dropout_rate': 0.12140119570907465, 'learning_rate': 0.0046591316224395465}. Best is trial 5 with value: 0.3873552983081033.\n",
            "[I 2024-04-29 23:17:31,703] Trial 7 finished with value: 0.3619768477292965 and parameters: {'n_hidden': 3, 'n_units': 206, 'dropout_rate': 0.35057996150122916, 'learning_rate': 0.012478308216252027}. Best is trial 5 with value: 0.3873552983081033.\n",
            "[I 2024-04-29 23:17:39,992] Trial 8 finished with value: 0.3619768477292965 and parameters: {'n_hidden': 2, 'n_units': 215, 'dropout_rate': 0.4406643509109279, 'learning_rate': 0.07660569846660767}. Best is trial 5 with value: 0.3873552983081033.\n",
            "[I 2024-04-29 23:17:50,543] Trial 9 finished with value: 0.3619768477292965 and parameters: {'n_hidden': 5, 'n_units': 103, 'dropout_rate': 0.4110449560715851, 'learning_rate': 0.033432052799943275}. Best is trial 5 with value: 0.3873552983081033.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_hidden': 3, 'n_units': 171, 'dropout_rate': 0.23599819193024688, 'learning_rate': 0.000823571972729172}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the best model on test data\n",
        "best_model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        output = best_model(X_batch)\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total += y_batch.size(0)\n",
        "        correct += (predicted == y_batch).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f\"Accuracy of the best model: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crAw60hSwK0W",
        "outputId": "c5e38b0a-c1dc-448e-9309-601ad35614a6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the best model: 0.030276046304541407\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mP_AWTsrJDP7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}