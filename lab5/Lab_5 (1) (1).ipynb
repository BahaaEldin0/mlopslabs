{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGExifOvrMXe",
        "outputId": "12a92121-a3bf-436e-8b48-4feba072c33f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.6.0-py3-none-any.whl (379 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m379.9/379.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.28)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.2-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.10.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.2 alembic-1.13.1 colorlog-6.8.2 optuna-3.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1V33RyparJOH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import optuna\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import reuters\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load the Reuters dataset\n",
        "max_len = 300  # Adjust based on the dataset analysis\n",
        "(X_train, y_train), (X_test, y_test) = reuters.load_data(path=\"reuters.npz\")\n",
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)\n",
        "\n",
        "# Convert the data to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# Create a DataLoader\n",
        "batch_size = 32\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, n_hidden, n_units, dropout_rate):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        layers = [nn.Linear(input_dim, n_units), nn.ReLU(), nn.Dropout(dropout_rate)]\n",
        "\n",
        "        for _ in range(n_hidden):\n",
        "            layers += [nn.Linear(n_units, n_units), nn.ReLU(), nn.Dropout(dropout_rate)]\n",
        "\n",
        "        layers += [nn.Linear(n_units, output_dim)]\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # Flatten the input\n",
        "        logits = self.network(x)\n",
        "        return logits\n",
        "\n",
        "def create_model(trial, input_dim, output_dim):\n",
        "    n_hidden = trial.suggest_int('n_hidden', 2, 5)  # Increased range for hidden layers\n",
        "    n_units = trial.suggest_int('n_units', 64, 256)  # Increased range for units per layer\n",
        "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)  # Suggesting dropout rate\n",
        "    model = NeuralNetwork(input_dim, output_dim, n_hidden, n_units, dropout_rate)\n",
        "    return model\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    model = create_model(trial, X_train.shape[1], len(np.unique(y_train)))\n",
        "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            output = model(X_batch)\n",
        "            loss = criterion(output, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            output = model(X_batch)\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total += y_batch.size(0)\n",
        "            correct += (predicted == y_batch).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=10, n_jobs=-1)  # Reduced the number of trials for brevity\n",
        "\n",
        "print(study.best_params)\n",
        "\n",
        "# Create a model with the best hyperparameters found\n",
        "best_model = create_model(study.best_trial, X_train.shape[1], len(np.unique(y_train)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCuQrqS7wKTv",
        "outputId": "8ee24535-25a4-4833-be5b-b4997d8e195d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-03-18 22:52:57,671] A new study created in memory with name: no-name-9d89c6d2-4dad-4aaf-8f87-de2bbfa44371\n",
            "<ipython-input-14-97aba967f213>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
            "[I 2024-03-18 22:53:13,401] Trial 1 finished with value: 0.3619768477292965 and parameters: {'n_hidden': 4, 'n_units': 66, 'dropout_rate': 0.3324998009426059, 'learning_rate': 0.00066216081563118}. Best is trial 1 with value: 0.3619768477292965.\n",
            "[I 2024-03-18 22:53:17,743] Trial 0 finished with value: 0.2929652715939448 and parameters: {'n_hidden': 2, 'n_units': 244, 'dropout_rate': 0.4327079786993041, 'learning_rate': 1.4881262718462555e-05}. Best is trial 1 with value: 0.3619768477292965.\n",
            "[I 2024-03-18 22:53:26,037] Trial 2 finished with value: 0.36108637577916297 and parameters: {'n_hidden': 2, 'n_units': 82, 'dropout_rate': 0.4611616875851442, 'learning_rate': 0.0004485649380436393}. Best is trial 1 with value: 0.3619768477292965.\n",
            "[I 2024-03-18 22:53:39,228] Trial 3 finished with value: 0.41228851291184326 and parameters: {'n_hidden': 3, 'n_units': 206, 'dropout_rate': 0.12055976713878712, 'learning_rate': 0.0006228021148634648}. Best is trial 3 with value: 0.41228851291184326.\n",
            "[I 2024-03-18 22:53:40,898] Trial 4 finished with value: 0.3619768477292965 and parameters: {'n_hidden': 2, 'n_units': 83, 'dropout_rate': 0.28660365721859027, 'learning_rate': 0.022715634859805475}. Best is trial 3 with value: 0.41228851291184326.\n",
            "[I 2024-03-18 22:53:56,353] Trial 5 finished with value: 0.3655387355298308 and parameters: {'n_hidden': 3, 'n_units': 181, 'dropout_rate': 0.3762819339918291, 'learning_rate': 0.0006144480310512422}. Best is trial 3 with value: 0.41228851291184326.\n",
            "[I 2024-03-18 22:54:02,486] Trial 6 finished with value: 0.36153161175422976 and parameters: {'n_hidden': 2, 'n_units': 206, 'dropout_rate': 0.2183466672306624, 'learning_rate': 0.0032753456526392073}. Best is trial 3 with value: 0.41228851291184326.\n",
            "[I 2024-03-18 22:54:08,414] Trial 7 finished with value: 0.3624220837043633 and parameters: {'n_hidden': 2, 'n_units': 112, 'dropout_rate': 0.3215724520501301, 'learning_rate': 0.00014185935425963517}. Best is trial 3 with value: 0.41228851291184326.\n",
            "[I 2024-03-18 22:54:22,639] Trial 8 finished with value: 0.22395369545859306 and parameters: {'n_hidden': 3, 'n_units': 208, 'dropout_rate': 0.30942614579561273, 'learning_rate': 1.0340453761887881e-05}. Best is trial 3 with value: 0.41228851291184326.\n",
            "[I 2024-03-18 22:54:24,217] Trial 9 finished with value: 0.3619768477292965 and parameters: {'n_hidden': 2, 'n_units': 138, 'dropout_rate': 0.39787183018068506, 'learning_rate': 0.00542265219678839}. Best is trial 3 with value: 0.41228851291184326.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_hidden': 3, 'n_units': 206, 'dropout_rate': 0.12055976713878712, 'learning_rate': 0.0006228021148634648}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the best model on test data\n",
        "best_model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        output = best_model(X_batch)\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total += y_batch.size(0)\n",
        "        correct += (predicted == y_batch).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f\"Accuracy of the best model: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crAw60hSwK0W",
        "outputId": "50e675a9-4357-46c4-c8c1-200caf26e881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the best model: 0.018699910952804988\n"
          ]
        }
      ]
    }
  ]
}